{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb30006",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31382083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import praw\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"USER_AGENT\"),\n",
    ")\n",
    "\n",
    "# Parameters\n",
    "TOP_N_REPLIES = 1\n",
    "MIN_REPLY_SCORE = 2\n",
    "\n",
    "subreddit_flair_map = {\n",
    "    \"linux4noobs\": None,\n",
    "    \"linuxquestions\": None,\n",
    "    \"linux\": \"Discussion\",\n",
    "    \"Fedora\": \"Support\",\n",
    "    \"linuxmint\": \"Support Request\",  # handles space in flair\n",
    "    \"archlinux\": \"SUPPORT\",\n",
    "    \"arch\": \"Help/Support\"\n",
    "}\n",
    "OUTPUT_JSONL = \"../data/reddit/{}_posts.jsonl\"\n",
    "\n",
    "\n",
    "def collect_replies(comment):\n",
    "    replies = []\n",
    "    if hasattr(comment, \"body\") and comment.body:\n",
    "        replies.append({\n",
    "            \"text\": comment.body.strip(),\n",
    "            \"timestamp\": datetime.fromtimestamp(comment.created_utc, tz=timezone.utc).isoformat(),\n",
    "            \"upvotes\": comment.score,\n",
    "        })\n",
    "    for reply in comment.replies:\n",
    "        replies.extend(collect_replies(reply))\n",
    "    return replies\n",
    "\n",
    "\n",
    "def scrape_posts(SUBREDDIT, FLAIR):\n",
    "    records = []\n",
    "    subreddit = reddit.subreddit(SUBREDDIT)\n",
    "\n",
    "    print(f\"ğŸ” Scanning all posts in r/{SUBREDDIT}... (may take a while)\")\n",
    "\n",
    "    for post in subreddit.top(time_filter=\"all\", limit=None):\n",
    "        if FLAIR is not None and post.link_flair_text != FLAIR:\n",
    "                continue\n",
    "        if not post.is_self: # skip media, links, images, etc.\n",
    "            continue\n",
    "        \n",
    "        if not post.selftext.strip() and not post.title.strip(): # skip useless posts\n",
    "            continue\n",
    "\n",
    "        title = post.title.strip()\n",
    "        body = post.selftext.strip()\n",
    "\n",
    "        try:\n",
    "            post.comments.replace_more(limit=None)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error loading comments for {post.id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        replies = []\n",
    "        for top_comment in post.comments:\n",
    "            replies.extend(collect_replies(top_comment))\n",
    "\n",
    "        replies = [r for r in replies if r[\"upvotes\"] >= MIN_REPLY_SCORE]\n",
    "        replies = sorted(replies, key=lambda x: x[\"upvotes\"], reverse=True)[:TOP_N_REPLIES]\n",
    "\n",
    "        if not replies:\n",
    "            continue\n",
    "\n",
    "        answer = \"\\n\\n\".join([r[\"text\"] for r in replies])\n",
    "\n",
    "        records.append({\n",
    "            \"id\": post.id,\n",
    "            \"instruction\": title,\n",
    "            \"input\": body,\n",
    "            \"output\": answer,\n",
    "        })\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def save_to_jsonl(records, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for record in records:\n",
    "            json.dump(record, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3732cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scanning all posts in r/linux4noobs... (may take a while)\n",
      "ğŸ’¾ Saved 562 records to ../data/reddit/linux4noobs_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/linuxquestions... (may take a while)\n",
      "ğŸ’¾ Saved 929 records to ../data/reddit/linuxquestions_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/linux... (may take a while)\n",
      "ğŸ’¾ Saved 15 records to ../data/reddit/linux_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/Fedora... (may take a while)\n",
      "ğŸ’¾ Saved 10 records to ../data/reddit/Fedora_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/linuxmint... (may take a while)\n",
      "ğŸ’¾ Saved 0 records to ../data/reddit/linuxmint_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/archlinux... (may take a while)\n",
      "ğŸ’¾ Saved 15 records to ../data/reddit/archlinux_posts.jsonl\n",
      "ğŸ” Scanning all posts in r/arch... (may take a while)\n",
      "ğŸ’¾ Saved 79 records to ../data/reddit/arch_posts.jsonl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for subreddit, flair in subreddit_flair_map.items():\n",
    "        data = scrape_posts(subreddit, flair)\n",
    "        save_to_jsonl(data, OUTPUT_JSONL.format(subreddit))\n",
    "        print(f\"ğŸ’¾ Saved {len(data)} records to {OUTPUT_JSONL.format(subreddit)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
